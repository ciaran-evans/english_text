{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from skimage.io import imread\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, Flatten, Lambda, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "\n",
    "num_classes = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = imread('../images/omniglot/images_background/Alphabet_of_the_Magi/character01/0709_01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_images(filepath, image_dims=(105,105)):\n",
    "    \"\"\"\n",
    "    Get pairs of images from a csv which contains paths in the first 2 columns.\n",
    "    \"\"\"\n",
    "    arr = np.genfromtxt(filepath, dtype = np.unicode_, delimiter = ',')\n",
    "    out = np.empty((len(arr), 2, image_dims[0], image_dims[1]))\n",
    "    out[:,0] = [imread(pp) for pp in arr[:,0]]\n",
    "    out[:,1] = [imread(pp) for pp in arr[:,1]]\n",
    "    out = out.astype('float32')\n",
    "    \n",
    "    return out\n",
    "\n",
    "def interleave_arrays(arr1, arr2):\n",
    "    \"\"\"\n",
    "    Create an array with alternating rows from two arrays.\n",
    "    Assumes the two arrays have the same dtype and dimensions.\n",
    "    \"\"\"\n",
    "    newshape = list(arr1.shape)\n",
    "    newshape[0] *= 2\n",
    "    out = np.empty(newshape, dtype = arr1.dtype)\n",
    "    out[0::2] = arr1\n",
    "    out[1::2] = arr2\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 4,  5,  6],\n",
       "       [ 7,  8,  9],\n",
       "       [10, 11, 12]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing interleave_arrays()\n",
    "arr1 = np.array([[1,2,3],[7,8,9]])\n",
    "arr2 = np.array([[4,5,6],[10,11,12]])\n",
    "interleave_arrays(arr1, arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing get_images()\n",
    "arr = get_images('../images/omniglot/test_same_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11ea11780>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCjYFSQWbgqSCTUFS4f8B5Z92hf4cuogAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e8b1f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(arr[0,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n",
    "\n",
    "def l1_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.maximum(K.sum(K.abs(x - y), axis=1, keepdims=True), K.epsilon())\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def l1_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return(shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) +\n",
    "                  (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=64, kernel_size = (10, 10), activation='relu')(input)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(filters = 128, kernel_size = (7,7), activation = 'relu')(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(filters = 128, kernel_size = (4,4), activation = 'relu')(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(filters = 256, kernel_size = (4,4))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation ='sigmoid')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating training and test data\n",
    "image_dims = (105, 105)\n",
    "\n",
    "train_same = get_images('../images/omniglot/train_same_pairs.csv', image_dims)\n",
    "train_diff = get_images('../images/omniglot/train_different_pairs.csv', image_dims)\n",
    "test_same = get_images('../images/omniglot/test_same_pairs.csv', image_dims)\n",
    "test_diff = get_images('../images/omniglot/test_different_pairs.csv', image_dims)\n",
    "\n",
    "tr_pairs = interleave_arrays(train_same, train_diff) / 255\n",
    "te_pairs = interleave_arrays(test_same, test_diff) / 255\n",
    "tr_y = np.zeros((len(tr_pairs),))\n",
    "tr_y[0::2] = 1\n",
    "te_y = np.zeros((len(te_pairs),))\n",
    "te_y[0::2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network definition\n",
    "input_shape = (105, 105, 1)\n",
    "base_network = create_base_network(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(l1_distance,\n",
    "                  output_shape=l1_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "sig_out = Dense(1, activation='sigmoid')(distance)\n",
    "\n",
    "model = Model([input_a, input_b], sig_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_11 to have 4 dimensions, but got array with shape (30000, 105, 105)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-8ca97a456424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# compute final accuracy on training and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1591\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1594\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1424\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1427\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1428\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    108\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_11 to have 4 dimensions, but got array with shape (30000, 105, 105)"
     ]
    }
   ],
   "source": [
    "# train\n",
    "rms = RMSprop()  # optimization method: variant of SGD\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
    "\n",
    "# compute final accuracy on training and test sets\n",
    "y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(tr_y, y_pred)\n",
    "y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(te_y, y_pred)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
