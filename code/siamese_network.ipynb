{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from skimage.io import imread\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, Flatten, Lambda, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "\n",
    "num_classes = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZVwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe3f776dcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = imread('../images/omniglot/images_background/Alphabet_of_the_Magi/character01/0709_01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_images(filepath, image_dims=(105,105)):\n",
    "    \"\"\"\n",
    "    Get pairs of images from a csv which contains paths in the first 2 columns.\n",
    "    \"\"\"\n",
    "    arr = np.genfromtxt(filepath, dtype = np.unicode_, delimiter = ',')\n",
    "    out = np.empty((len(arr), 2, image_dims[0], image_dims[1]))\n",
    "    out[:,0] = [imread(pp) for pp in arr[:,0]]\n",
    "    out[:,1] = [imread(pp) for pp in arr[:,1]]\n",
    "    out = out.astype('float32')\n",
    "    \n",
    "    return out\n",
    "\n",
    "def interleave_arrays(arr1, arr2):\n",
    "    \"\"\"\n",
    "    Create an array with alternating rows from two arrays.\n",
    "    Assumes the two arrays have the same dtype and dimensions.\n",
    "    \"\"\"\n",
    "    newshape = list(arr1.shape)\n",
    "    newshape[0] *= 2\n",
    "    out = np.empty(newshape, dtype = arr1.dtype)\n",
    "    out[0::2] = arr1\n",
    "    out[1::2] = arr2\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 4,  5,  6],\n",
       "       [ 7,  8,  9],\n",
       "       [10, 11, 12]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing interleave_arrays()\n",
    "arr1 = np.array([[1,2,3],[7,8,9]])\n",
    "arr2 = np.array([[4,5,6],[10,11,12]])\n",
    "interleave_arrays(arr1, arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing get_images()\n",
    "arr = get_images('../images/omniglot/test_same_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11ea11780>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCjYFSQWbgqSCTUFS4f8B5Z92hf4cuogAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e8b1f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(arr[0,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n",
    "\n",
    "def l1_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.maximum(K.sum(K.abs(x - y), axis=1, keepdims=True), K.epsilon())\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def l1_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return(shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) +\n",
    "                  (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=64, kernel_size = (10, 10), activation='relu')(input)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(filters = 128, kernel_size = (7,7), activation = 'relu')(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(filters = 128, kernel_size = (4,4), activation = 'relu')(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(filters = 256, kernel_size = (4,4))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation ='sigmoid')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating training and test data\n",
    "image_dims = (105, 105)\n",
    "\n",
    "train_same = get_images('../images/omniglot/train_same_pairs.csv', image_dims)\n",
    "train_diff = get_images('../images/omniglot/train_different_pairs.csv', image_dims)\n",
    "test_same = get_images('../images/omniglot/test_same_pairs.csv', image_dims)\n",
    "test_diff = get_images('../images/omniglot/test_different_pairs.csv', image_dims)\n",
    "\n",
    "tr_pairs = interleave_arrays(train_same, train_diff) / 255\n",
    "te_pairs = interleave_arrays(test_same, test_diff) / 255\n",
    "tr_y = np.zeros((len(tr_pairs),))\n",
    "tr_y[0::2] = 1\n",
    "te_y = np.zeros((len(te_pairs),))\n",
    "te_y[0::2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADmpJREFUeJzt3W+MHPV9x/H3t3cQFyIENgYZ262N\nZCVBSAZ0oiRUFcKJIBTFPAgVKEqt1JKf0IakqVLTPkCV+iBIUSCVUloLkrgV4k8MCoiiuJFLFPVB\nDWdiEcAhuJDCYQcbCkmVVk1Mvn2wc+3+Lne9u53dndm990s63c3s7M33xvCZ7/z2t7ORmUjSrF9r\nugBJ7WIoSCoYCpIKhoKkgqEgqWAoSCoYCpIKAwmFiLg2Il6MiKMRsXsQ+5A0GNHvyUsRMQH8EPgI\nMAM8DdycmS/0dUeSBmJyAL/zcuBoZr4MEBEPANuBBUPh3NUTuWnjaQMoRdKsQ8/+95uZuXax7QYR\nCuuB17qWZ4DfmrtRROwCdgH8xvpJntq/cQClSJo1se7ovy1lu0GMKcQ8637lGiUz92TmVGZOrV0z\nMYAyJPViEKEwA3Sf9jcAxwawH0kDMIhQeBrYEhGbI+J04CbgsQHsR9IA9H1MITNPRcQfAvuBCeCr\nmfl8v/cjaTAGMdBIZj4BPDGI3y1psJzRKKlgKEgqGAqSCoaCpIKhIKlgKEgqGAqSCoaCpIKhIKlg\nKEgqGAqSCoaCpIKhIKlgKEgqGAqSCoaCpIKhIKlgKEgqGAqSCoaCpIKhIKlgKEgqGAqSCoaCpIKh\nIKlgKEgqGAqSCoaCpIKhIKlgKEgqGAqSCoaCpELPoRARGyPiyYg4EhHPR8St1frVEfHtiHip+n5O\n/8qVNGh1OoVTwOcy8wPAFcAtEXERsBs4kJlbgAPVsqQR0XMoZObxzHym+vk/gCPAemA7sLfabC9w\nQ90iJQ1PX8YUImITcClwEDg/M49DJziA8/qxD0nDUTsUIuK9wMPAZzLzp8t43q6ImI6I6ZNvvVu3\nDEl9UisUIuI0OoFwX2Y+Uq1+IyLWVY+vA07M99zM3JOZU5k5tXbNRJ0yJPVRnVcfArgXOJKZX+p6\n6DFgR/XzDuDR3suTNGyTNZ57JfBJ4PsRcbha92fAF4CHImIn8CpwY70SJQ1Tz6GQmf8MxAIPb+v1\n90pqljMaJRUMBUkFQ0FSwVCQVDAUJBUMBUmFOvMUNEDXXHBJ0yW02v5jhxffSD2xU5BUMBQ0kq65\n4BK7qQExFCQVDAWNNDuG/jMUJBUMBUkFQ0FSwXkKLeK18fI5X6H/7BQkFewURtS4niHtlppnpyCp\nYKcwombPqOPSMSy3QxiXv7uN7BQkFQwFSQUvHzRSvGwYPDsFSQU7hRbpPgsudeBt1AccfQmyfewU\nJBUMhTHhW4jVL4aCpIJjCi01O0aw3LP/3O3bOtbgZKX2slOQVLBTaLleO4Y26uVvsEMYPjsFSQU7\nhRFRd4yhyTPuOHQ5K4mdgqRC7U4hIiaAaeD1zLw+IjYDDwCrgWeAT2bmz+vuRx2jNMZQp0bHEprT\nj07hVuBI1/IdwJ2ZuQV4G9jZh31IGpJaoRARG4DfBe6plgO4GthXbbIXuKHOPjS//ccOL+tsOioz\nHpf7d6n/6nYKdwGfB35ZLa8B3snMU9XyDLB+vidGxK6ImI6I6ZNvvVuzDEn90vOYQkRcD5zIzEMR\ncdXs6nk2zfmen5l7gD0AU1tXzbuN+m8Yr0Y4H2G01RlovBL4WERcB6wCzqLTOZwdEZNVt7ABOFa/\nTEnDEpn1T9JVp/An1asP3wAezswHIuJvgGcz86//v+dPbV2VT+3fWLuOlazX8YJ+nqHtENptYt3R\nQ5k5tdh2g5in8KfAH0fEUTpjDPcOYB+SBqQvMxoz8zvAd6qfXwYu78fv1eB1n909awuc0ShpDt/7\nMCbmnuWHOSfBsYTxYqcgqWCnMKZ6eY/EcucwePek8WSnIKlgKEgqePmgZRuFN1apd3YKkgp2CmOu\nnwOObZhKrcGzU5BUsFPQguqOHdghjCY7BUkFO4UVYpg3fLVDGG12CpIKhoKkgqEgqeCYwgozyLEF\nxxLGg52CpIKdwgrVz47BDmG82ClIKtgpqGd2COPJTkFSwU5hhes+2y93fGHu9nYO48FOQVLBTmGF\n8y5KmstOQVLBTmGFGkSH4BjDeLBTkFQwFCQVDAVJBccUVpgmPnjWsYXRYqcgqVCrU4iIs4F7gIuB\nBP4AeBF4ENgE/Aj4vcx8u1aVqq1Oh1D38x/sGEZL3U7hy8C3MvP9wFbgCLAbOJCZW4AD1bKkEdFz\nKETEWcDvAPcCZObPM/MdYDuwt9psL3BD3SIlDU+dy4cLgZPA1yJiK3AIuBU4PzOPA2Tm8Yg4r36Z\nasJC7X6vN2jp3t5Lifaqc/kwCVwG3J2ZlwI/YxmXChGxKyKmI2L65Fvv1ihDUj/VCYUZYCYzD1bL\n++iExBsRsQ6g+n5ividn5p7MnMrMqbVrJmqUoX7bf+zwks7kS91uPtdccIlvxmqpnkMhM38MvBYR\n76tWbQNeAB4DdlTrdgCP1qpQ0lDVnbz0R8B9EXE68DLwKTpB81BE7AReBW6suQ/V4NlYy1UrFDLz\nMDA1z0Pb6vxeSc1xmvOY6qVD6HV8YJgfXqvBc5qzpIKdwphp8mzdS8fgFOj2sVOQVDAU1Hd15i+o\neYaCpIJjCmNiuWMJbTuTO7bQHnYKkgp2CiOq11cZ2n4mtmNonp2CpIKhMGbaNPLfplq0dIaCpIJj\nCmNmobEGz9haKjsFSQU7hREzivMRfE/EaLFTkFSwU9DQdJ/1l9o1+PH2w2enIKlgpzCmPKOqV3YK\nkgqGgqSCoaBG9DoF2g+RGTxDQVLBgcYRMa5nx7ofVuuAav/ZKUgqGApqBccY2sNQkFRwTGHMrNRr\nbMcY+sdOQVLBTqHlVtr1sh9W2zw7BUkFO4Uxs9LPsI4t1FerU4iIz0bE8xHxXETcHxGrImJzRByM\niJci4sGIOL1fxUoavJ5DISLWA58GpjLzYmACuAm4A7gzM7cAbwM7+1HoSuPr72pK3TGFSeDXI2IS\nOAM4DlwN7Kse3wvcUHMfkoao5zGFzHw9Ir4IvAr8F/CPwCHgncw8VW02A6yvXeUKYWegNqhz+XAO\nsB3YDFwAnAl8dJ5Nc4Hn74qI6YiYPvnWu72WIanP6rz68GHglcw8CRARjwAfAs6OiMmqW9gAHJvv\nyZm5B9gDMLV11bzBsVLYIahN6owpvApcERFnREQA24AXgCeBj1fb7AAerVeipGGqM6ZwMCL2Ac8A\np4Dv0Tnz/wPwQET8ZbXu3n4UOo7sENRGtSYvZebtwO1zVr8MXF7n90pqjjMaG+SsO7WR732QVDAU\nJBUMBUkFQ0FSwVCQVDAUJBUMBUkFQ0FSwVCQVDAUJBUMBUkFQ0FSwVCQVDAUJBUMBUkFQ0FSwVCQ\nVDAUJBUMBUkFQ0FSwVCQVDAUJBUMBUkFQ0FSwVCQVDAUJBUMBUkFQ0FSwVCQVDAUJBUMBUkFQ0FS\nYdFQiIivRsSJiHiua93qiPh2RLxUfT+nWh8R8VcRcTQino2IywZZvKT+W0qn8HXg2jnrdgMHMnML\ncKBaBvgosKX62gXc3Z8yJQ3LoqGQmd8F/n3O6u3A3urnvcANXev/Ljv+BTg7Itb1q1hJg9frmML5\nmXkcoPp+XrV+PfBa13Yz1bpfERG7ImI6IqZPvvVuj2VI6rd+DzTGPOtyvg0zc09mTmXm1No1E30u\nQ1Kveg2FN2YvC6rvJ6r1M8DGru02AMd6L0/SsPUaCo8BO6qfdwCPdq3//epViCuAn8xeZkgaDZOL\nbRAR9wNXAedGxAxwO/AF4KGI2Am8CtxYbf4EcB1wFPhP4FMDqFnSAC0aCpl58wIPbZtn2wRuqVuU\npOY4o1FSwVCQVDAUJBUMBUmF6IwNNlxExEngZ8CbTdeyBOfS/jqtsX9Goc6l1vibmbl2sY1aEQoA\nETGdmVNN17GYUajTGvtnFOrsd41ePkgqGAqSCm0KhT1NF7BEo1CnNfbPKNTZ1xpbM6YgqR3a1ClI\naoFWhEJEXBsRL1b3dty9+DMGLyI2RsSTEXEkIp6PiFur9fPen7LhWici4nsR8Xi1vDkiDlY1PhgR\np7egxrMjYl9E/KA6ph9s27GMiM9W/9bPRcT9EbGqDcdy2PdJbTwUImIC+Aqd+zteBNwcERc1WxUA\np4DPZeYHgCuAW6q6Fro/ZZNuBY50Ld8B3FnV+Daws5GqSl8GvpWZ7we20qm3NccyItYDnwamMvNi\nYAK4iXYcy68zzPukZmajX8AHgf1dy7cBtzVd1zx1Pgp8BHgRWFetWwe82HBdG6r/KK4GHqdz96s3\ngcn5jm9DNZ4FvEI1htW1vjXHkv+7leBqOu8efhy4pi3HEtgEPLfYsQP+Frh5vu2W+tV4p8Ay7uvY\nlIjYBFwKHGTh+1M25S7g88Avq+U1wDuZeapabsPxvBA4CXytusy5JyLOpEXHMjNfB75I5/4gx4Gf\nAIdo37GcVfs+qQtpQygs+b6OTYiI9wIPA5/JzJ82XU+3iLgeOJGZh7pXz7Np08dzErgMuDszL6Uz\npb0Nl13/q7om3w5sBi4AzqTTis/V9LFcTO1//zaEQmvv6xgRp9EJhPsy85Fq9UL3p2zClcDHIuJH\nwAN0LiHuonNr/dkb6LTheM4AM5l5sFreRyck2nQsPwy8kpknM/MXwCPAh2jfsZw1sPuktiEUnga2\nVKO8p9MZ3Hms4ZqIiADuBY5k5pe6Hlro/pRDl5m3ZeaGzNxE57j9U2Z+AngS+Hi1WaM1AmTmj4HX\nIuJ91aptwAu06FjSuWy4IiLOqP7tZ2ts1bHsMrj7pDY1sDNnEOU64IfAvwJ/3nQ9VU2/TaftehY4\nXH1dR+ea/QDwUvV9ddO1VvVeBTxe/Xwh8BSde2V+A3hPC+q7BJiujuc3gXPadiyBvwB+ADwH/D3w\nnjYcS+B+OuMcv6DTCexc6NjRuXz4SvX/0vfpvJqyrP05o1FSoQ2XD5JaxFCQVDAUJBUMBUkFQ0FS\nwVCQVDAUJBUMBUmF/wGPVSbJuPtn2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe41e941150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tr_pairs[1,1,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network definition\n",
    "# Input shape is dim. of image and number of channels (1 channel here)\n",
    "input_shape = (105, 105, 1)\n",
    "base_network = create_base_network(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(l1_distance,\n",
    "                  output_shape=l1_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "sig_out = Dense(1, activation='sigmoid')(distance)\n",
    "\n",
    "model = Model([input_a, input_b], sig_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " 2048/30000 [=>............................] - ETA: 1:02:30 - loss: 0.3386 - accuracy: 0.4961"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3b04e4e62280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           validation_data=([te_pairs[:, 0].reshape(10000, 105, 105, 1), \n\u001b[0;32m----> 8\u001b[0;31m                             te_pairs[:, 1].reshape(10000, 105, 105, 1)], te_y))\n\u001b[0m",
      "\u001b[0;32m/home/ciaran/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/ciaran/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ciaran/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ciaran/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ciaran/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ciaran/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ciaran/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ciaran/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rms = RMSprop()  # optimization method: variant of SGD\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "\n",
    "# Note that the training and test images need to be reshaped to add channel information (1 channel)\n",
    "model.fit([tr_pairs[:, 0].reshape(30000, 105, 105, 1), \n",
    "           tr_pairs[:, 1].reshape(30000, 105, 105, 1)], tr_y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          validation_data=([te_pairs[:, 0].reshape(10000, 105, 105, 1), \n",
    "                            te_pairs[:, 1].reshape(10000, 105, 105, 1)], te_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute final accuracy on training and test sets\n",
    "## NOTE: I haven't tried this section yet, so we might need to reshape the data here too\n",
    "y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(tr_y, y_pred)\n",
    "y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(te_y, y_pred)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
